#!/bin/bash

# Setup script for Rust ML project
# This script helps you configure your environment files

set -e  # Exit on error

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                                                â•‘"
echo "â•‘     ðŸ¦€ RUST ML v2.0 - Environment Setup Helper ðŸ¦€              â•‘"
echo "â•‘                                                                â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# ============================================================================
# Step 1: Check if PyTorch is installed
# ============================================================================

echo "ðŸ“‹ Step 1: Checking PyTorch installation..."

if ! command -v python3 &> /dev/null; then
    echo "âŒ Python3 not found. Please install Python3 first."
    exit 1
fi

if ! python3 -c "import torch" 2>/dev/null; then
    echo "âŒ PyTorch not found. Installing PyTorch with CUDA support..."
    echo ""
    echo "Run one of these commands:"
    echo "  pip install torch --index-url https://download.pytorch.org/whl/cu121"
    echo "  pip install torch --index-url https://download.pytorch.org/whl/cu118"
    exit 1
fi

echo "âœ… PyTorch is installed"

# ============================================================================
# Step 2: Detect PyTorch paths
# ============================================================================

echo ""
echo "ðŸ“‹ Step 2: Detecting PyTorch installation paths..."

TORCH_PATH=$(python3 -c "import torch; print(torch.__path__[0])" 2>/dev/null)

if [ -z "$TORCH_PATH" ]; then
    echo "âŒ Could not detect PyTorch path"
    exit 1
fi

TORCH_LIB="${TORCH_PATH}/lib"
NVIDIA_BASE=$(dirname "$TORCH_PATH")/nvidia

echo "âœ… Detected paths:"
echo "   PyTorch:    $TORCH_PATH"
echo "   Torch lib:  $TORCH_LIB"
echo "   NVIDIA:     $NVIDIA_BASE"

# ============================================================================
# Step 3: Check CUDA availability
# ============================================================================

echo ""
echo "ðŸ“‹ Step 3: Checking CUDA availability..."

CUDA_AVAILABLE=$(python3 -c "import torch; print(torch.cuda.is_available())" 2>/dev/null)

if [ "$CUDA_AVAILABLE" = "True" ]; then
    echo "âœ… CUDA is available in PyTorch"
    CUDA_VERSION=$(python3 -c "import torch; print(torch.version.cuda)" 2>/dev/null)
    DEVICE_NAME=$(python3 -c "import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')" 2>/dev/null)
    echo "   CUDA version: $CUDA_VERSION"
    echo "   GPU: $DEVICE_NAME"
else
    echo "âš ï¸  CUDA not available in PyTorch"
    echo "   Project will run on CPU (slower)"
fi

# ============================================================================
# Step 4: Create environment files
# ============================================================================

echo ""
echo "ðŸ“‹ Step 4: Creating environment files..."

# Create cuda_env.sh
if [ -f "cuda_env.sh" ]; then
    echo "âš ï¸  cuda_env.sh already exists. Creating backup..."
    cp cuda_env.sh cuda_env.sh.backup
fi

cat > cuda_env.sh << EOF
# CUDA environment setup for Rust+PyTorch
# Auto-generated by setup.sh
# Source this file before building or running: source cuda_env.sh

TORCH_LIB="$TORCH_LIB"
NVIDIA_BASE="$NVIDIA_BASE"

export LIBTORCH="$TORCH_PATH"
export LIBTORCH_USE_PYTORCH=1

export LD_LIBRARY_PATH="\${TORCH_LIB}:\${NVIDIA_BASE}/cuda_runtime/lib:\${NVIDIA_BASE}/cublas/lib:\${NVIDIA_BASE}/cudnn/lib:\${NVIDIA_BASE}/cufft/lib:\${NVIDIA_BASE}/curand/lib:\${NVIDIA_BASE}/cusolver/lib:\${NVIDIA_BASE}/cusparse/lib:\${NVIDIA_BASE}/cuda_nvrtc/lib:\${NVIDIA_BASE}/cuda_cupti/lib:\$LD_LIBRARY_PATH"

export LD_PRELOAD="\${TORCH_LIB}/libtorch_cuda.so:\${TORCH_LIB}/libc10_cuda.so"

echo "âœ“ CUDA environment configured"
echo "  LIBTORCH: \$LIBTORCH"
echo "  Now you can run: cargo run --release"
EOF

echo "âœ… Created cuda_env.sh"

# Create run_cuda.sh
if [ -f "run_cuda.sh" ]; then
    echo "âš ï¸  run_cuda.sh already exists. Creating backup..."
    cp run_cuda.sh run_cuda.sh.backup
fi

cat > run_cuda.sh << EOF
#!/bin/bash

# Python PyTorch CUDA kÃ¼tÃ¼phanelerinin yolu
TORCH_LIB="$TORCH_LIB"
NVIDIA_BASE="$NVIDIA_BASE"

# TÃ¼m NVIDIA CUDA kÃ¼tÃ¼phanelerini ekle
export LD_LIBRARY_PATH="\${TORCH_LIB}:\${NVIDIA_BASE}/cuda_runtime/lib:\${NVIDIA_BASE}/cublas/lib:\${NVIDIA_BASE}/cudnn/lib:\${NVIDIA_BASE}/cufft/lib:\${NVIDIA_BASE}/curand/lib:\${NVIDIA_BASE}/cusolver/lib:\${NVIDIA_BASE}/cusparse/lib:\${NVIDIA_BASE}/cuda_nvrtc/lib:\${NVIDIA_BASE}/cuda_cupti/lib:\$LD_LIBRARY_PATH"

# libtorch_cuda.so'nun yÃ¼klenmesini zorla
export LD_PRELOAD="\${TORCH_LIB}/libtorch_cuda.so:\${TORCH_LIB}/libc10_cuda.so"

echo "LD_LIBRARY_PATH set"
echo "LD_PRELOAD set to force load CUDA libraries"
echo ""

./target/release/rust-ml
EOF

chmod +x run_cuda.sh
echo "âœ… Created run_cuda.sh (executable)"

# ============================================================================
# Step 5: Build project
# ============================================================================

echo ""
echo "ðŸ“‹ Step 5: Building project..."
echo ""

source cuda_env.sh
cargo build --release

if [ $? -eq 0 ]; then
    echo ""
    echo "âœ… Build successful!"
else
    echo ""
    echo "âŒ Build failed. Please check the errors above."
    exit 1
fi

# ============================================================================
# Summary
# ============================================================================

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                    âœ… Setup Complete! âœ…                        â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ðŸ“ Created files:"
echo "   âœ“ cuda_env.sh"
echo "   âœ“ run_cuda.sh"
echo ""
echo "ðŸš€ To run the project:"
echo "   ./run_cuda.sh"
echo ""
echo "Or manually:"
echo "   source cuda_env.sh"
echo "   cargo run --release"
echo ""
echo "ðŸŽ¯ The project will run 13 AI/ML techniques in ~2 seconds!"
echo ""
